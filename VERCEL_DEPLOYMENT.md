# Despliegue en Vercel

## ğŸ“‹ Requisitos Previos

1. Cuenta en [Vercel](https://vercel.com)
2. Vercel CLI instalado: `npm install -g vercel`
3. Tu OpenAI API Key

## ğŸš€ Despliegue

### OpciÃ³n 1: Despliegue desde el CLI

```bash
# Desde la raÃ­z del proyecto /Users/antonio/Work/ai/00
vercel
```

Sigue las instrucciones en pantalla para vincular tu proyecto.

### OpciÃ³n 2: Despliegue desde GitHub

1. Sube tu cÃ³digo a un repositorio de GitHub
2. Ve a [vercel.com/new](https://vercel.com/new)
3. Importa tu repositorio
4. Vercel detectarÃ¡ automÃ¡ticamente la configuraciÃ³n

## âš™ï¸ Variables de Entorno

**IMPORTANTE**: No necesitas configurar `OPENAI_API_KEY` en Vercel porque la API key se envÃ­a desde el frontend en cada request.

Si prefieres usar una API key del servidor (mÃ¡s seguro):

1. Ve a tu proyecto en Vercel
2. Settings â†’ Environment Variables
3. Agrega: `OPENAI_API_KEY` con tu clave

Luego modifica `api/app.py` para usar la variable de entorno en lugar de la que viene del request.

## ğŸ—ï¸ Arquitectura del Despliegue

```
/                    â†’ Frontend (Vite build estÃ¡tico)
/api/*               â†’ Backend (FastAPI serverless)
```

### Frontend
- Se sirve como sitio estÃ¡tico desde `frontend/dist/`
- Build automÃ¡tico durante el despliegue
- Todos los assets optimizados

### Backend
- Funciona como serverless functions
- Endpoint: `https://tu-proyecto.vercel.app/api/chat`
- Health check: `https://tu-proyecto.vercel.app/api/health`

## âš ï¸ Limitaciones en Vercel

### 1. Timeout de Funciones
- **Hobby plan**: 10 segundos mÃ¡ximo
- **Pro plan**: 60 segundos mÃ¡ximo
- Las respuestas largas pueden cortarse

### 2. Streaming
- El streaming funciona pero con limitaciones
- Respuestas muy largas pueden no funcionar correctamente en el plan gratuito

### 3. Cold Starts
- La primera request despuÃ©s de inactividad puede ser lenta
- El servidor se "duerme" despuÃ©s de un tiempo sin uso

## ğŸ”§ ConfiguraciÃ³n Post-Despliegue

DespuÃ©s del despliegue, actualiza la URL del API en el frontend:

1. Ve a tu app desplegada
2. En el panel de configuraciÃ³n, ingresa:
   - **API URL**: `https://tu-proyecto.vercel.app/api/chat`
3. Haz clic en "Probar" para verificar la conexiÃ³n

## ğŸ› Troubleshooting

### Error: "No se puede conectar con el backend"
- Verifica que el despliegue haya terminado correctamente
- Revisa los logs en Vercel Dashboard
- AsegÃºrate de usar la URL correcta (debe incluir `/api/chat`)

### Error: "Function timeout"
- Reduce el tamaÃ±o de las respuestas
- Considera usar modelos mÃ¡s rÃ¡pidos (gpt-4o-mini)
- Upgrade a Vercel Pro para timeouts mÃ¡s largos

### Error durante el build
- Verifica que `requirements.txt` tenga todas las dependencias
- Revisa los logs de build en Vercel Dashboard

## ğŸ“Š Monitoreo

Vercel provee:
- Analytics de trÃ¡fico
- Logs en tiempo real
- MÃ©tricas de rendimiento

Accede a estos desde el Dashboard de Vercel.

## ğŸ”’ Seguridad

### RecomendaciÃ³n: Mover API Keys al servidor

Para mayor seguridad, modifica `api/app.py`:

```python
import os

# En lugar de recibir api_key del request:
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
```

Y elimina `api_key` del modelo `ChatRequest`.

Luego configura `OPENAI_API_KEY` en las variables de entorno de Vercel.

## ğŸ“ Comandos Ãštiles

```bash
# Despliegue en producciÃ³n
vercel --prod

# Despliegue de preview
vercel

# Ver logs en tiempo real
vercel logs

# Ver lista de despliegues
vercel ls

# Eliminar proyecto
vercel remove
```

## ğŸŒ URLs de Ejemplo

DespuÃ©s del despliegue:
- **App**: `https://beyond-chatgpt.vercel.app`
- **API Health**: `https://beyond-chatgpt.vercel.app/api/health`
- **API Chat**: `https://beyond-chatgpt.vercel.app/api/chat`

Â¡Tu app estÃ¡ lista para usarse en producciÃ³n! ğŸ‰

