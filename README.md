# ğŸ¤– OpenAI Chat Interface

Una aplicaciÃ³n moderna de chat con OpenAI que incluye frontend en React/Vite y backend en FastAPI.

## ğŸ“ Estructura del Proyecto

```
ai/00/
â”œâ”€â”€ api/                    # Backend FastAPI
â”‚   â”œâ”€â”€ app.py             # AplicaciÃ³n principal
â”‚   â”œâ”€â”€ requirements.txt   # Dependencias Python para Vercel
â”‚   â””â”€â”€ vercel.json        # ConfiguraciÃ³n Vercel del API
â”œâ”€â”€ frontend/              # Frontend React + Vite
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ pyproject.toml         # Dependencias Python (desarrollo local)
â”œâ”€â”€ vercel.json           # ConfiguraciÃ³n Vercel principal
â””â”€â”€ deploy-vercel.sh      # Script de despliegue
```

## ğŸš€ Inicio RÃ¡pido

### Desarrollo Local

#### Backend
```bash
# Instalar dependencias con uv
uv sync

# Iniciar servidor
uv run python api/app.py

# O con auto-reload
uv run uvicorn api.app:app --reload
```

El backend estarÃ¡ disponible en `http://localhost:8000`

#### Frontend
```bash
cd frontend
npm install
npm run dev
```

El frontend estarÃ¡ disponible en `http://localhost:3000`

### ConfiguraciÃ³n

1. Abre `http://localhost:3000`
2. Ingresa tu OpenAI API Key
3. Configura la URL del API: `http://localhost:8000/api/chat`
4. Haz clic en "Probar" para verificar la conexiÃ³n
5. Â¡Comienza a chatear!

## ğŸŒ Despliegue en Vercel

### OpciÃ³n 1: CLI (Recomendado)

```bash
# Instalar Vercel CLI si no lo tienes
npm install -g vercel

# Desde la raÃ­z del proyecto
./deploy-vercel.sh

# O manualmente
vercel          # Para preview
vercel --prod   # Para producciÃ³n
```

### OpciÃ³n 2: GitHub

1. Sube el cÃ³digo a GitHub
2. Ve a [vercel.com/new](https://vercel.com/new)
3. Importa tu repositorio
4. Vercel detectarÃ¡ automÃ¡ticamente la configuraciÃ³n
5. Â¡Despliega!

### ConfiguraciÃ³n Post-Despliegue

DespuÃ©s del despliegue, tu app estarÃ¡ en: `https://tu-proyecto.vercel.app`

**Actualiza la configuraciÃ³n en el frontend:**
- API URL: `https://tu-proyecto.vercel.app/api/chat`
- Haz clic en "Probar" para verificar la conexiÃ³n

## ğŸ“š DocumentaciÃ³n

- [Backend API](/api/README.md) - DocumentaciÃ³n del API FastAPI
- [Frontend](/frontend/README.md) - DocumentaciÃ³n del frontend
- [Despliegue Vercel](/VERCEL_DEPLOYMENT.md) - GuÃ­a detallada de despliegue

## ğŸ”§ CaracterÃ­sticas

### Backend (FastAPI)
- âœ… API REST con streaming
- âœ… CORS configurado
- âœ… Health check endpoint
- âœ… Soporte para mÃºltiples modelos GPT
- âœ… DocumentaciÃ³n automÃ¡tica (Swagger)

### Frontend (React + Vite)
- âœ… Interfaz moderna y responsive
- âœ… Streaming de respuestas en tiempo real
- âœ… ValidaciÃ³n de conexiÃ³n con backend
- âœ… Indicador de estado de API
- âœ… Panel de configuraciÃ³n
- âœ… Tailwind CSS

## ğŸ“¡ Endpoints del API

### Chat
```
POST /api/chat
Content-Type: application/json

{
  "developer_message": "You are a helpful assistant.",
  "user_message": "Hello!",
  "model": "gpt-4o-mini",
  "api_key": "sk-..."
}
```

### Health Check
```
GET /api/health

Response: {"status": "ok"}
```

## ğŸ”’ Seguridad

**âš ï¸ Importante:** Por defecto, la API key se envÃ­a desde el frontend. Para mayor seguridad en producciÃ³n:

1. Configura `OPENAI_API_KEY` como variable de entorno en Vercel
2. Modifica `api/app.py` para usar la variable de entorno
3. Elimina el campo `api_key` del modelo de request

Ver [VERCEL_DEPLOYMENT.md](/VERCEL_DEPLOYMENT.md#-seguridad) para detalles.

## âš ï¸ Limitaciones en Vercel

- **Timeout**: 10 segundos (Hobby) / 60 segundos (Pro)
- **Streaming**: Funciona pero con limitaciones de tiempo
- **Cold Starts**: Primera request puede ser lenta

## ğŸ› Troubleshooting

### Error: "Failed to fetch"
- âœ… Verifica que el backend estÃ© corriendo
- âœ… Revisa que la URL del API sea correcta
- âœ… Verifica CORS si usas un dominio diferente

### Error: "API Desconectada"
- âœ… El indicador rojo significa que el backend no responde
- âœ… Haz clic en "Probar" para verificar la conexiÃ³n
- âœ… Revisa los logs del servidor

### Error en Vercel
- âœ… Revisa los logs en Vercel Dashboard
- âœ… Verifica que `requirements.txt` estÃ© actualizado
- âœ… Confirma que las rutas en `vercel.json` sean correctas

## ğŸ› ï¸ TecnologÃ­as

- **Backend**: FastAPI, Python 3.11, OpenAI SDK, Uvicorn
- **Frontend**: React 18, TypeScript, Vite, Tailwind CSS
- **Deployment**: Vercel
- **Package Managers**: uv (Python), npm (JavaScript)

## ğŸ“ Scripts Disponibles

### Backend
```bash
uv run python api/app.py       # Iniciar servidor
uv run uvicorn api.app:app --reload  # Con auto-reload
```

### Frontend
```bash
npm run dev        # Servidor de desarrollo
npm run build      # Build para producciÃ³n
npm run preview    # Preview del build
npm run lint       # Linter
```

### Despliegue
```bash
./deploy-vercel.sh      # Despliegue interactivo
vercel                  # Preview deployment
vercel --prod          # Production deployment
vercel logs            # Ver logs
```

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue primero para discutir los cambios propuestos.

---

**Â¿Necesitas ayuda?** Revisa la documentaciÃ³n en las carpetas `/api` y `/frontend` o abre un issue.
